{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T  "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    Experience = namedtuple('Experience', ('state', 'action', 'next_state', 'reward'))\n",
    "    \n",
    "    def __init__(self, img_height, img_width):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=img_height*img_width*3, out_features=24)   \n",
    "        self.fc2 = nn.Linear(in_features=24, out_features=32)\n",
    "        self.out = nn.Linear(in_features=32, out_features=2)\n",
    "    \n",
    "    def forward(self, t):\n",
    "        t = t.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "    \n",
    "    def push(self, experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.push_count % self.capacity] = experience\n",
    "        self.push_count += 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def can_provide_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyStrategy():\n",
    "    def __init__(self, start, end, decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay = decay\n",
    "\n",
    "    def get_exploration_rate(self, current_step):\n",
    "        return self.end + (self.start - self.end) * \\\n",
    "            math.exp(-1. * current_step * self.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, strategy, num_actions):\n",
    "        self.current_step = 0\n",
    "        self.strategy = strategy\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def select_action(self, state, policy_net):\n",
    "        rate = self.strategy.get_exploration_rate(self.current_step)\n",
    "        self.current_step += 1\n",
    "\n",
    "        if rate > random.random():\n",
    "            return random.randrange(self.num_actions) # explore      \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                return policy_net(state).argmax(dim=1).item() # exploit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleEnvManager():\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.env = gym.make('CartPole-v0').unwrapped\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "\n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        return self.env.render(mode)\n",
    "\n",
    "    def num_actions_available(self):\n",
    "        return self.env.action_space.n\n",
    "\n",
    "    def take_action(self, action):        \n",
    "        _, reward, self.done, _ = self.env.step(action.item())\n",
    "        return torch.tensor([reward], device=self.device)\n",
    "\n",
    "    def just_starting(self):\n",
    "        return self.current_screen is None\n",
    "\n",
    "    def get_state(self):\n",
    "        if self.just_starting() or self.done:\n",
    "            self.current_screen = self.get_processed_screen()\n",
    "            black_screen = torch.zeros_like(self.current_screen)\n",
    "            return black_screen\n",
    "        else:\n",
    "            s1 = self.current_screen\n",
    "            s2 = self.get_processed_screen()\n",
    "            self.current_screen = s2\n",
    "            return s2 - s1\n",
    "\n",
    "    def get_screen_height(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[2]\n",
    "\n",
    "    def get_screen_width(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[3]\n",
    "\n",
    "    def get_processed_screen(self):\n",
    "        screen = self.render('rgb_array').transpose((2, 0, 1)) # PyTorch expects CHW\n",
    "        screen = self.crop_screen(screen)\n",
    "        return self.transform_screen_data(screen)\n",
    "    \n",
    "    def crop_screen(self, screen):\n",
    "        screen_height = screen.shape[1]\n",
    "\n",
    "        # Strip off top and bottom\n",
    "        top = int(screen_height * 0.4)\n",
    "        bottom = int(screen_height * 0.8)\n",
    "        screen = screen[:, top:bottom, :]\n",
    "        return screen\n",
    "    \n",
    "    def transform_screen_data(self, screen):       \n",
    "        # Convert to float, rescale, convert to tensor\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "        screen = torch.from_numpy(screen)\n",
    "\n",
    "        # Use torchvision package to compose image transforms\n",
    "        resize = T.Compose([\n",
    "            T.ToPILImage()\n",
    "            ,T.Resize((40,90))\n",
    "            ,T.ToTensor()\n",
    "        ])\n",
    "\n",
    "        return resize(screen).unsqueeze(0).to(self.device) # add a batch dimension (BCHW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "em = CartPoleEnvManager(device)\n",
    "em.reset()\n",
    "screen = em.render('rgb_array')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen)\n",
    "plt.title('Non-processed screen example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1, 2, 0).cpu(), interpolation='none')\n",
    "plt.title('Processed screen example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}